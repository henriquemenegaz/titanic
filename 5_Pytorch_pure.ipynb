{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 1. XGBoost new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Definition                      | Key                                         |\n",
    "|----------|---------------------------------|---------------------------------------------|\n",
    "| survival | Survival                        | 0 = No, 1 = Yes                             |\n",
    "| pclass   | Ticket class                    | 1 = 1st, 2 = 2nd, 3 = 3rd                   |\n",
    "| sex      | Sex                             |                                             |\n",
    "| Age      | Age in years                    |                                             |\n",
    "| sibsp    | # of siblings / spouses aboard the Titanic |                               |\n",
    "| parch    | # of parents / children aboard the Titanic  |                               |\n",
    "| ticket   | Ticket number                   |                                             |\n",
    "| fare     | Passenger fare                  |                                             |\n",
    "| cabin    | Cabin number                    |                                             |\n",
    "| embarked | Port of Embarkation             | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.12.1\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Henrique Menegaz\n",
      "\n",
      "numpy : 1.26.3\n",
      "pandas: 2.1.4\n",
      "torch : 2.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Henrique Menegaz\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test files into pandas dataframes\n",
    "df_original = pd.read_csv('./titanic/train.csv')\n",
    "df_submission_original = pd.read_csv('./titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = df_original.mode().iloc[0]\n",
    "df_original.fillna(modes, inplace=True)\n",
    "df_submission_original.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Family</th>\n",
       "      <th>Alone</th>\n",
       "      <th>TicketFreq</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>ABC</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>ABC</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare    Cabin Embarked   LogFare Deck  Family  \\\n",
       "0      0         A/5 21171   7.2500  B96 B98        S  2.110213  ABC       1   \n",
       "1      0          PC 17599  71.2833      C85        C  4.280593  ABC       1   \n",
       "2      0  STON/O2. 3101282   7.9250  B96 B98        S  2.188856  ABC       0   \n",
       "3      0            113803  53.1000     C123        S  3.990834  ABC       1   \n",
       "4      0            373450   8.0500  B96 B98        S  2.202765  ABC       0   \n",
       "\n",
       "   Alone  TicketFreq Title  \n",
       "0  False           1    Mr  \n",
       "1  False           1   Mrs  \n",
       "2   True           1  Miss  \n",
       "3  False           2   Mrs  \n",
       "4   True           1    Mr  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "    df['Deck'] = df.Cabin.str[0].map(dict(A=\"ABC\",B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))\n",
    "    df['Family'] = df.SibSp+df.Parch\n",
    "    df['Alone'] = df.Family==0\n",
    "    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    df['Title'] = df.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "    df['Title'] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\"))\n",
    "\n",
    "add_features(df_original)\n",
    "add_features(df_submission_original)\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"Sex\",\"Pclass\",\"Embarked\",\"Deck\", \"Title\", 'Alone']\n",
    "numerical_cols = ['Age', 'SibSp', 'Parch', 'LogFare', 'TicketFreq', 'Family']\n",
    "y_cols = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_original[categorical_cols + numerical_cols].copy()\n",
    "#df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "df_y = df_original[y_cols].copy()\n",
    "#y = y.astype('category')\n",
    "\n",
    "df_submission = df_submission_original[categorical_cols + numerical_cols].copy()\n",
    "df_submission[categorical_cols] = df_submission[categorical_cols]#.astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    107\n",
       "2     93\n",
       "3    218\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission['Pclass'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Hot Encoding to categorical variables\n",
    "# Create an instance of the OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "\n",
    "#encoded\n",
    "encoded_train = encoder.fit_transform(df_x[categorical_cols])\n",
    "encoded_test = encoder.transform(df_submission[categorical_cols])\n",
    "\n",
    "# Fit and transform the categorical columns using the encoder\n",
    "df_train_encoded = pd.DataFrame(encoded_train.toarray())\n",
    "df_test_encoded = pd.DataFrame(encoded_test.toarray())\n",
    "\n",
    "# Assign column names to the encoded DataFrame\n",
    "df_train_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "df_test_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Concatenate the encoded DataFrame with the original DataFrame\n",
    "df_x = pd.concat([df_x, df_train_encoded], axis=1)\n",
    "df_submission = pd.concat([df_submission, df_test_encoded], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "df_x.drop(categorical_cols, axis=1, inplace=True)\n",
    "df_submission.drop(categorical_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standard scaling to the numerical features\n",
    "df_x[numerical_cols] = pd.DataFrame(scaler.fit_transform(df_x[numerical_cols]),columns=numerical_cols)\n",
    "df_submission[numerical_cols] = pd.DataFrame(scaler.transform(df_submission[numerical_cols]),columns=numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset Class\n",
    "class CreateFeaturesDataset(Dataset):\n",
    "\tdef __init__(self, df):\n",
    "\t\tsuper().__init__()\t\t\n",
    "\t\tself.data = torch.tensor(df.to_numpy(),dtype=torch.float32)\n",
    "\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.data.shape[0]\n",
    "\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tfeatures = self.data[idx, :-1]\n",
    "\t\tlabel = self.data[idx, -1]\n",
    "\t\treturn features, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model class\n",
    "class Net(nn.Module):\n",
    "\tdef __init__(self,n_x,n_y):\n",
    "\t\tsuper(Net, self).__init__()\n",
    "\t\tself.fc1 = nn.Linear(n_x, 16)\n",
    "\t\tself.fc2 = nn.Linear(16, 8)\n",
    "\t\tself.fc3 = nn.Linear(8, n_y)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = nn.functional.relu(self.fc1(x))\n",
    "\t\tx = nn.functional.relu(self.fc2(x))\n",
    "\t\tx = nn.functional.sigmoid(self.fc3(x))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# As observações são minhas e podem estar erradas porque as coloquei quando ainda estava estudando.\n",
    "def train(model, device, train_dataloader, optim, epoch,criterion):\n",
    "    model.train() # put in training model. It updates gradients\n",
    "    for b_i, (X, y) in enumerate(train_dataloader):\n",
    "        # y = y.type(torch.LongTensor)\n",
    "        X, y = X.to(device), y.to(device) # send to device\n",
    "        optim.zero_grad() # reset gradients from last batch\n",
    "        pred_prob = model(X) # foward propagation        \n",
    "        # get \n",
    "        loss = criterion(pred_prob[:,0].double(), y.double()) # loss\n",
    "        loss.backward() # backward propagation. Compute gradients\n",
    "        optim.step() # Update the model with gradients\n",
    "        # Create online log\n",
    "        if b_i % 10 == 0:\n",
    "            print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.6f}'.format(\n",
    "                epoch, b_i * len(X), len(train_dataloader.dataset),\n",
    "                100. * b_i / len(train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device= \"cpu\"\n",
    "\n",
    "\n",
    "# Instatiate Dataset\n",
    "df_x_y = pd.concat([df_x,df_y],axis=1)\n",
    "dataset_train = CreateFeaturesDataset(df_x_y)\n",
    "\n",
    "# Instatiate DataLoader\n",
    "dataloader_train = DataLoader(\n",
    "\tdataset_train,\n",
    "\tbatch_size=32,\n",
    "\tshuffle=True,\n",
    ")\n",
    "\n",
    "# Instantiate model\n",
    "model = Net(df_x.shape[1],1).to(device)\n",
    "\n",
    "# Instantiate Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [0/891 (0%)]\t training loss: 41.514576\n",
      "epoch: 1 [320/891 (36%)]\t training loss: 41.446097\n",
      "epoch: 1 [640/891 (71%)]\t training loss: 31.103419\n",
      "epoch: 2 [0/891 (0%)]\t training loss: 24.139258\n",
      "epoch: 2 [320/891 (36%)]\t training loss: 41.319381\n",
      "epoch: 2 [640/891 (71%)]\t training loss: 34.309567\n"
     ]
    }
   ],
   "source": [
    "## Model Training\n",
    "for epoch in range(1, 3):\n",
    "    train(model, device, dataloader_train, optimizer, epoch,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model parameters\n",
    "torch.save(model.state_dict(),'./models/model-params.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model parameters\n",
    "model = Net(df_x.shape[1],1).to(device)\n",
    "model.load_state_dict(torch.load('./models/model-params.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict first case of df_submission\n",
    "X_submission = torch.tensor(df_submission.to_numpy(),dtype=torch.float32).to(device)\n",
    "predictions_submission = model(X_submission).round().cpu().detach().numpy()[:,0].T\n",
    "predictions_submission\n",
    "df_final = pd.DataFrame({\n",
    "    'PassengerId': df_submission_original['PassengerId'],\n",
    "    'Survived': predictions_submission.astype(int)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\n",
      "892,0\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,0\n",
      "897,0\n",
      "898,0\n",
      "899,0\n",
      "900,0\n"
     ]
    }
   ],
   "source": [
    "df_final.to_csv('submission_csvs/sub5_pytorch_pure',index=False)\n",
    "!head submission_csvs/sub5_pytorch_pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/hmtm/.kaggle/kaggle.json'\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.14 / client 1.6.6)\n",
      "100%|██████████████████████████████████████| 2.77k/2.77k [00:00<00:00, 5.22kB/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f submission_csvs/sub5_pytorch_pure -m \"Simple Net with Pytorch\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
